{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac55f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilias\\miniconda3\\envs\\pcp\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz  \n",
    "import pathlib as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "folder = r\"C:\\Users\\Ilias\\Desktop\\WB Internship\\PCP\\cv\"\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2  \n",
    "    return df_1\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    get names of all pdf files in the folder\n",
    "    \"\"\"\n",
    "    os.chdir(folder)\n",
    "    files = os.listdir()\n",
    "    files = [x for x in files if x.endswith(\".pdf\")]\n",
    "    return files \n",
    "\n",
    "def compute_years_edu(edu):\n",
    "    years = 0\n",
    "    if 'b.a.' in edu:\n",
    "        years = years + 4\n",
    "    if 'b.b.a.' in edu:\n",
    "        years = years + 4 \n",
    "    if 'b.com.' in edu:\n",
    "        years = years +3 \n",
    "    if 'b.e.' in edu:\n",
    "        years = years + 4 \n",
    "    if 'b.s.' in edu:\n",
    "        years = years + 4\n",
    "    if 'b.sc.' in edu:\n",
    "        years = years + 4 \n",
    "    if 'l.l.b.' in edu:\n",
    "        years = years +3 \n",
    "    if 'l.l.m.' in edu:\n",
    "        years = years + 2 \n",
    "    if 'm.a.' in edu:\n",
    "        years = years +2 \n",
    "    if 'm.b.a.' in edu:\n",
    "        years = years + 2 \n",
    "    if 'm.com.' in edu:\n",
    "        years = years + 2\n",
    "    if 'm.p.a.' in edu:\n",
    "        years = years + 2 \n",
    "    if 'm.phil.' in edu:\n",
    "        years = years + 2  \n",
    "    if 'm.s.' in edu:\n",
    "        years = years +2 \n",
    "    if 'm.sc.' in edu:\n",
    "        years = years + 2 \n",
    "    if 'mbbs' in edu:\n",
    "        years = years + 5\n",
    "    if 'p.g.d' in edu:\n",
    "        years = years + 4 \n",
    "    return years\n",
    "\n",
    "def create_lang_col(df):\n",
    "    df['worker_eng'] = df['languages'].apply(lambda x: 1 if 'english' in x else 0)\n",
    "    df['worker_urdu'] = df['languages'].apply(lambda x: 1 if 'urdu' in x else 0)\n",
    "    df['worker_kashmiri'] = df['languages'].apply(lambda x: 1 if 'kashmiri' in x else 0)\n",
    "    df['worker_pashto'] = df['languages'].apply(lambda x: 1 if 'pashto' in x else 0)\n",
    "    df['worker_punjabi'] = df['languages'].apply(lambda x: 1 if 'punjabi' in x else 0)\n",
    "    df['worker_sindhi'] = df['languages'].apply(lambda x: 1 if 'sindhi' in x else 0)\n",
    "\n",
    "\n",
    "def extract_training_table(text_training):\n",
    "    if len(text_training[2:]) > 0:        \n",
    "        df_tr = pd.DataFrame({'training':text_training[1:]})\n",
    "        df_tr = df_tr.training.str.split(pat='\\n', expand = True)\n",
    "        df_tr.columns = df_tr.iloc[0]\n",
    "        df_tr = df_tr.add_prefix('worker_training_')\n",
    "        df_tr = df_tr.iloc[1:,0:5]\n",
    "        df_tr.columns= df_tr.columns.str.lower()             \n",
    "    else: \n",
    "        df_tr = pd.DataFrame({'worker_training_institute': [''], 'worker_training_country': [''], \n",
    "                              'worker_training_from' :[''], 'worker_training_to':[''], 'worker_training_course':['']})\n",
    "    return df_tr\n",
    "\n",
    " \n",
    "def make_dfs(text_demo, text_qualification, text_training, text_post):\n",
    "# extract demographics information\n",
    "    df_demo = pd.DataFrame([text_demo])\n",
    "    df_demo.rename(columns = {0: 'worker_name', 1: 'worker_occupational', 2: 'worker_dob', 3:'date_of_joining_govt_service',\n",
    "                        4: 'length_of_service', 5: 'worker_current_position', 6: 'date_of_present_appointment', \n",
    "                        7: 'worker_organization', 8:'seniority_no'}, inplace = True)\n",
    "\n",
    "    # remove text redundancy\n",
    "    df_demo[['worker_name', 'worker_occupational', 'worker_dob', 'date_of_joining_govt_service', \n",
    "        'date_of_present_appointment', 'seniority_no']] = df_demo[['worker_name', 'worker_occupational', 'worker_dob', 'date_of_joining_govt_service', \n",
    "        'date_of_present_appointment', 'seniority_no']].apply(lambda x: x.str.extract(r'\\:(.*)', expand=False))\n",
    "\n",
    "    df_demo['worker_prov_dist'] = df_demo.iloc[:,0].str.extract(r'\\[(.*)\\]', expand=False)\n",
    "    df_demo['worker_name'] = df_demo['worker_name'].apply(lambda x: x.split(sep='[')[0])\n",
    "    df_demo['worker_birth_district'] = df_demo['worker_prov_dist'].str.extract(r'\\((.*)\\)', expand=False)\n",
    "    df_demo['worker_birht_province'] = df_demo['worker_prov_dist'].str.split(pat='(', expand = True)[0]\n",
    "    df_demo[['worker_dob', 'worker_superannuation']] = df_demo['worker_dob'].str.split('DATE OF SUPERANNUATION:', expand = True)\n",
    "    df_demo.drop(columns='worker_prov_dist', inplace = True)\n",
    "    \n",
    "    # extract qualification information\n",
    "    df_qual = pd.DataFrame({'qualification':text_qualification[2:]})\n",
    "    df_qual = df_qual.qualification.str.split(pat='\\n', expand = True)\n",
    "    df_qual.rename(columns = {0: 'academic_professional', 1: 'languages'}, inplace = True)\n",
    "    df_qual = df_qual[['academic_professional','languages']]\n",
    "    \n",
    "    # extract training information\n",
    "    df_tr = extract_training_table(text_training)\n",
    "    \n",
    "    # extract posting information\n",
    "    df_post = pd.DataFrame({'posting':text_post[2:]})\n",
    "    df_post = df_post.posting.str.split(pat='\\n', expand = True)\n",
    "    df_post.rename(columns = {0: 'worker_post', 1: 'BS', 2: 'post_from', 3:'post_to',\n",
    "                        4: 'worker_post_organization'}, inplace = True)\n",
    "\n",
    "\n",
    "    return df_demo, df_qual, df_tr, df_post\n",
    "\n",
    "def clean_col(df):\n",
    "    \"\"\"\n",
    "    strip from the dateframe whitespace, commas, slashes and new lines\n",
    "    \"\"\"\n",
    "    df = df.apply(lambda x: x.str.strip(', ').str.lower())\n",
    "    df = df.apply(lambda x: x.str.strip('\\\\'))\n",
    "    df = df.apply(lambda x: x.str.strip('\\n'))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8496e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_files(folder)\n",
    "df_post_dict = pd.read_excel(r'C:\\Users\\Ilias\\Desktop\\WB Internship\\PCP\\dictionary\\position_grouped_dictionary.xlsx')\n",
    "df_demo_all = []\n",
    "df_post_all = []\n",
    "df_tr_all = []\n",
    "for i in names: \n",
    "    with fitz.open(i) as doc:\n",
    "        lines = []\n",
    "        for page in doc:\n",
    "            page_text_block = page.get_text('blocks')\n",
    "            for i in page_text_block:\n",
    "                lines.append(i[4])\n",
    "        \n",
    "            idxs_qual = [i for i, item in enumerate(lines) if item.startswith('QUALIFICATION')]\n",
    "            idxs_train = [i for i, item in enumerate(lines) if item.startswith('TRAINING DETAILS')]\n",
    "            idxs_post = [i for i, item in enumerate(lines) if item.startswith('POSTINGS')]\n",
    "            text_demo = lines[1:idxs_qual[0]]\n",
    "            text_qualification = lines[idxs_qual[0]:idxs_train[0]]\n",
    "            text_training = lines[idxs_train[0]:idxs_post[0]] \n",
    "            text_post = lines[idxs_post[0]:]\n",
    "            if len(text_demo) == 8:\n",
    "                text_demo.insert(7,'')\n",
    "            \n",
    "            # creating tables from individual lists     \n",
    "            df_demo, df_qual, df_tr, df_post = make_dfs(text_demo, text_qualification, text_training, text_post)\n",
    "            \n",
    "            # combining demographics data with qualification data\n",
    "            df_demo_comb = pd.concat([df_demo, df_qual], axis = 1)\n",
    "            df_demo_all.append(df_demo_comb)\n",
    "            \n",
    "            # duplicating rows and then combining with training data\n",
    "            df_demo_comb_dupl_tr = pd.DataFrame(np.repeat(df_demo_comb.values, df_tr.shape[0], axis=0), \n",
    "                                 columns=df_demo_comb.columns)\n",
    "            \n",
    "            df_demo_comb_dupl_tr.reset_index(drop=True, inplace=True)\n",
    "            df_tr.reset_index(drop=True, inplace=True)\n",
    "            df_tr_comb = pd.concat([df_demo_comb_dupl_tr['worker_name'], df_tr], axis = 1)            \n",
    "            df_tr_all.append(df_tr_comb)\n",
    "            \n",
    "            #duplicating rows and then combining with posting data\n",
    "            df_demo_comb_dupl_post = pd.DataFrame(np.repeat(df_demo_comb.values, df_post.shape[0], axis=0), \n",
    "                     columns=df_demo_comb.columns)\n",
    "            df_post_comb = pd.concat([df_demo_comb_dupl_post['worker_name'], df_post], axis = 1)\n",
    "            df_post_all.append(df_post_comb)\n",
    "\n",
    "            \n",
    "df_demo_all = pd.concat(df_demo_all)  \n",
    "df_demo_all['length_of_service'] = df_demo_all['length_of_service'].apply(lambda x: x.split('HPSB')[0]) \n",
    "df_demo_all = clean_col(df_demo_all)\n",
    "df_demo_all['length_of_service']= df_demo_all['length_of_service'].apply(lambda x: x.split('length of service in ')[1])\n",
    "df_demo_all['worker_years_education'] = df_demo_all['academic_professional'].apply(lambda x: compute_years_edu(x))\n",
    "create_lang_col(df_demo_all)\n",
    "df_demo_all.drop_duplicates(inplace=True)\n",
    "\n",
    "df_demo_all['worker_current_bs'] = df_demo_all['worker_current_position'].apply(lambda x: re.findall('\\((.*?)\\)', x )[-1])\n",
    "df_demo_all['worker_current_position'] = df_demo_all['worker_current_position'].apply(lambda x:re.sub(r'\\((.*?)\\)','', x))\n",
    "df_demo_all['worker_current_position'] = df_demo_all['worker_current_position'].apply(lambda x: x.strip(' \\n')) \n",
    "\n",
    "df_demo_merged = pd.merge(df_demo_all, df_post_dict, how= 'left', left_on = 'worker_current_position', right_on = 'cv_post')\n",
    "df_demo_merged.drop(columns = 'cv_post', inplace = True)\n",
    "idx = df_demo_merged.columns.get_loc('worker_current_position')\n",
    "df_demo_merged.insert(loc=idx+1, column='worker_current_position_grouped', value=df_demo_merged.grouped_post)\n",
    "df_demo_merged.drop(columns = ['grouped_post'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_tr_all = pd.concat(df_tr_all)\n",
    "df_tr_all.drop_duplicates(inplace = True)\n",
    "df_tr_all = clean_col(df_tr_all)\n",
    "\n",
    "\n",
    "df_post_all = pd.concat(df_post_all)\n",
    "df_post_all.drop_duplicates(inplace= True)\n",
    "df_post_all = clean_col(df_post_all)\n",
    "\n",
    "# remove non-datetime values from the column post_from and post_to\n",
    "non_datetime_vls = df_post_all.post_to.str.contains(pat=r'[a-zA-Z]+')\n",
    "df_post_all.loc[non_datetime_vls,'worker_post_organization'] = df_post_all.loc[non_datetime_vls,'post_to'] + ';' + \\\n",
    "                                        df_post_all.loc[non_datetime_vls,'worker_post_organization']\n",
    "df_post_all.loc[non_datetime_vls,'post_to'] = ''\n",
    "non_datetime_vls_from = df_post_all.post_from.str.contains(pat=r'[a-zA-Z]+')\n",
    "df_post_all.loc[non_datetime_vls_from,'worker_post_organization'] = df_post_all.loc[non_datetime_vls_from,'post_from'] + ';' + \\\n",
    "                                        df_post_all.loc[non_datetime_vls_from,'worker_post_organization']\n",
    "df_post_all.loc[non_datetime_vls_from,'post_from'] = ''\n",
    "\n",
    "\n",
    "\n",
    "# add column, that contains grouped positions from the column post\n",
    "df_post_dict['grouped_post'] = df_post_dict['grouped_post'].str.strip()\n",
    "df_post_merged = pd.merge(df_post_all, df_post_dict, how= 'left', left_on = 'worker_post', right_on = 'cv_post')\n",
    "df_post_merged.drop(columns = 'cv_post', inplace = True)\n",
    "idx = df_post_merged.columns.get_loc('worker_post')\n",
    "df_post_merged.insert(loc=idx+1, column='worker_post_grouped', value=df_post_merged.grouped_post)\n",
    "df_post_merged.drop(columns = ['grouped_post',5], inplace = True)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('output.xlsx') as writer:  \n",
    "    df_demo_merged.to_excel(writer, sheet_name = 'Demographics', index = False)\n",
    "    df_post_merged.to_excel(writer, sheet_name='Postings', index = False)\n",
    "    df_tr_all.to_excel(writer, sheet_name='Trainings', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
